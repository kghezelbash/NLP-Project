{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55e6e4ec57ec457681e6e360e91985f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77d1472972f64596819abeaeb31a90a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6c264622d6d14900874ccff132611f98",
              "IPY_MODEL_b01269fb8bf74803acd4a71dfaceb9fb"
            ]
          }
        },
        "77d1472972f64596819abeaeb31a90a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c264622d6d14900874ccff132611f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_32e3e4a01deb4ad598c13faa102be2fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb354802e50a4bb3959aafe5c4104204"
          }
        },
        "b01269fb8bf74803acd4a71dfaceb9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_514c09a3efb14630a6dd439158901f22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 465kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73a207432fb845cbbcf0af63e4df055f"
          }
        },
        "32e3e4a01deb4ad598c13faa102be2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb354802e50a4bb3959aafe5c4104204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "514c09a3efb14630a6dd439158901f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73a207432fb845cbbcf0af63e4df055f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f4cbe06f0df4304848b8eda1ff37205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4441b5d1ad8e4ed9a76399a3732c505a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_899f7b0f364f406c825796b976412d08",
              "IPY_MODEL_e73b4999b92d456a92c1c994cededd0a"
            ]
          }
        },
        "4441b5d1ad8e4ed9a76399a3732c505a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "899f7b0f364f406c825796b976412d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc66aa411970476cae992dc0b4d56b52",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13e9c33b5ffa42fab8a084748c6be590"
          }
        },
        "e73b4999b92d456a92c1c994cededd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d980a54d1dbb48e4bb98704b9d833ce1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 192B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b9e83c5ce024b82adc0db10760fb3a2"
          }
        },
        "dc66aa411970476cae992dc0b4d56b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13e9c33b5ffa42fab8a084748c6be590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d980a54d1dbb48e4bb98704b9d833ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b9e83c5ce024b82adc0db10760fb3a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c4f925714374888ac146f16bfc288f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c568583126442bd852270276bfd7766",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff7c058e42494b1d9abace4743b61104",
              "IPY_MODEL_3c07481868964d2fb14ee8d661682022"
            ]
          }
        },
        "5c568583126442bd852270276bfd7766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff7c058e42494b1d9abace4743b61104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7890d14c058c431ab0b6b384570872db",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f34d1accba14e7b93b3dd6b9a26ce6b"
          }
        },
        "3c07481868964d2fb14ee8d661682022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b546063fcf841c988a73696bb5ce4e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 5.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dafb3745049143c8a33d01f040aa30d9"
          }
        },
        "7890d14c058c431ab0b6b384570872db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f34d1accba14e7b93b3dd6b9a26ce6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b546063fcf841c988a73696bb5ce4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dafb3745049143c8a33d01f040aa30d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3f8597df35a43ce98a28d56e25c8f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e09624e5f5c4387a79dc788f510683a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0f8fbf01350b49188e0bc9b8d84c6b4b",
              "IPY_MODEL_cd5a9d471431401eb6611dc5ce58d92e"
            ]
          }
        },
        "2e09624e5f5c4387a79dc788f510683a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f8fbf01350b49188e0bc9b8d84c6b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_47f8a164741143ed9179c6e6a242d7be",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e672ea092795409c844592ff41cfd383"
          }
        },
        "cd5a9d471431401eb6611dc5ce58d92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bc96583e2db4657b01532fc078056e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [01:54&lt;00:00, 4.99B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9732a8f2d6484056884157b0c63d42eb"
          }
        },
        "47f8a164741143ed9179c6e6a242d7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e672ea092795409c844592ff41cfd383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bc96583e2db4657b01532fc078056e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9732a8f2d6484056884157b0c63d42eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb57798fce5d4774903822352d7c6a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ddf9bb9eb66444e7bcf6c9fb13badc92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14b21152050d469bb2c5da1ccd149929",
              "IPY_MODEL_3453d35e94d7441d9a2a4f06b3a6d61f"
            ]
          }
        },
        "ddf9bb9eb66444e7bcf6c9fb13badc92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14b21152050d469bb2c5da1ccd149929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_321c334df06749a5bb020606ecac2551",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69cb3415614c4ae1b850c400c87cafae"
          }
        },
        "3453d35e94d7441d9a2a4f06b3a6d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acee8d5223eb4bf587d124a50b4b2d9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [01:53&lt;00:00, 3.82MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1d79a6612574773a9dde1ae1714ff22"
          }
        },
        "321c334df06749a5bb020606ecac2551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69cb3415614c4ae1b850c400c87cafae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acee8d5223eb4bf587d124a50b4b2d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1d79a6612574773a9dde1ae1714ff22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSoGxVIgUqh4",
        "outputId": "9742c1bf-127b-42c0-e33b-6573f0f1d5d5"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 9.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFGwaKU7EOXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72672d51-9758-46b1-ff7c-38c3a33b5a25"
      },
      "source": [
        "pip install -U deep_translator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deep_translator\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/71/b2939e3d1ccd91c5eba61718d183c607486089d509141e9cbe594cca873b/deep_translator-1.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from deep_translator) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from deep_translator) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deep_translator) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deep_translator) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deep_translator) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deep_translator) (3.0.4)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVsSO0bhl2Sb"
      },
      "source": [
        "# import library\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "import datetime\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo1qv4oJmHGm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RePZvDLZv6YC",
        "outputId": "7762e392-96ea-4abb-963f-aec3b401c481"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fejovEX9mV2z"
      },
      "source": [
        "with open(os.path.join('/content/drive/MyDrive/train-v1.1.json'), \"r\", encoding=\"utf-8\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "dataset = []\n",
        "for sample in input_data:\n",
        "    title = sample['title']\n",
        "    paragraphs = sample['paragraphs']\n",
        "    for paragraph in paragraphs:\n",
        "        context = GoogleTranslator(source='auto', target='fa').translate(paragraph['context'])\n",
        "        qas = paragraph['qas']\n",
        "        for qa in qas:\n",
        "            sample = {}\n",
        "            sample[\"title\"] = title\n",
        "            sample[\"context\"] = context\n",
        "            sample[\"question\"] = GoogleTranslator(source='en', target='fa').translate(qa['question'])\n",
        "\n",
        "            sample[\"id\"] = qa['id']\n",
        "            answer = qa['answers'][0]\n",
        "            if answer['text'].isdigit():\n",
        "                sample[\"answer_text\"] = answer['text']\n",
        "            else:\n",
        "                sample[\"answer_text\"] = GoogleTranslator(source='auto', target='fa').translate(answer['text'])\n",
        "\n",
        "            sample[\"answer_start\"] = answer['answer_start']\n",
        "            dataset.append(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4QXH9lMwfh6",
        "outputId": "7eac2571-ad32-46ed-da40-e11e2c68f9e8"
      },
      "source": [
        "wrapper = textwrap.TextWrapper(width=80) \n",
        "\n",
        "ex = dataset[888]\n",
        "\n",
        "print('Title:', ex['title'])\n",
        "print('ID:', ex['id'])\n",
        "\n",
        "print('\\n======== Question =========')\n",
        "print(ex['question'])\n",
        "\n",
        "print('\\n======== Context =========')\n",
        "print(wrapper.fill(ex['context']))\n",
        "\n",
        "print('\\n======== Answer =========')\n",
        "print(ex['answer_text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: Beyoncé\n",
            "ID: 56becb8d3aeaaa14008c9499\n",
            "\n",
            "======== Question =========\n",
            "چه کسی اولین زن موفق به دریافت جایزه بین المللی هنرمند در جوایز موسیقی آمریکا بود؟\n",
            "\n",
            "======== Context =========\n",
            "بیانسه جوایز بی شماری دریافت کرده است. وی به عنوان یک هنرمند انفرادی بیش از 15\n",
            "میلیون آلبوم در ایالات متحده و بیش از 118 میلیون آلبوم در سراسر جهان فروخته است\n",
            "(60 میلیون مورد دیگر با Destiny's Child) ، او را به یکی از پرفروش ترین هنرمندان\n",
            "موسیقی در تمام دوران تبدیل کرده است. انجمن صنعت ضبط امریکا (RIAA) بیانسه را به\n",
            "عنوان برترین هنرمند دارای گواهینامه 2000s با 64 گواهینامه معرفی کرد. آهنگ های\n",
            "\"Crazy in Love\" ، \"Single Ladies (Put a ring on it))\" ، \"Halo\" و \"Irreplaceable\"\n",
            "از پرفروش ترین تک آهنگ های تمام ادوار جهان است. در سال 2009 ، The Observer او را\n",
            "به عنوان Artist of the Decade و Billboard او را به عنوان هنرمند برتر زن و برترین\n",
            "آهنگ های رادیویی دهه معرفی کرد. در سال 2010 ، بیلبورد او را در لیست \"50 هنرمند\n",
            "برتر 25 سال گذشته R & B / Hip-Hop\" با شماره 15 قرار داد. در سال 2012 VH1 در رتبه\n",
            "سوم خود در لیست \"100 زن برتر موسیقی\" قرار گرفت. بیانسه اولین هنرمند زنی بود که\n",
            "با دریافت جایزه بین المللی هنرمند در جوایز موسیقی آمریکا مورد تقدیر قرار گرفت.\n",
            "وی همچنین جایزه افسانه را در جوایز موسیقی جهانی 2008 و جایزه هزاره بیلبورد را در\n",
            "جوایز موسیقی بیلبورد 2011 دریافت کرده است.\n",
            "\n",
            "======== Answer =========\n",
            "بیانسه\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "55e6e4ec57ec457681e6e360e91985f7",
            "77d1472972f64596819abeaeb31a90a5",
            "6c264622d6d14900874ccff132611f98",
            "b01269fb8bf74803acd4a71dfaceb9fb",
            "32e3e4a01deb4ad598c13faa102be2fe",
            "bb354802e50a4bb3959aafe5c4104204",
            "514c09a3efb14630a6dd439158901f22",
            "73a207432fb845cbbcf0af63e4df055f",
            "1f4cbe06f0df4304848b8eda1ff37205",
            "4441b5d1ad8e4ed9a76399a3732c505a",
            "899f7b0f364f406c825796b976412d08",
            "e73b4999b92d456a92c1c994cededd0a",
            "dc66aa411970476cae992dc0b4d56b52",
            "13e9c33b5ffa42fab8a084748c6be590",
            "d980a54d1dbb48e4bb98704b9d833ce1",
            "2b9e83c5ce024b82adc0db10760fb3a2",
            "1c4f925714374888ac146f16bfc288f9",
            "5c568583126442bd852270276bfd7766",
            "ff7c058e42494b1d9abace4743b61104",
            "3c07481868964d2fb14ee8d661682022",
            "7890d14c058c431ab0b6b384570872db",
            "6f34d1accba14e7b93b3dd6b9a26ce6b",
            "7b546063fcf841c988a73696bb5ce4e8",
            "dafb3745049143c8a33d01f040aa30d9"
          ]
        },
        "id": "gU7lcPADwjl9",
        "outputId": "a1706b00-a6b2-4eea-a917-03cfafb39a09"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-cased',\n",
        "    do_lower_case=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55e6e4ec57ec457681e6e360e91985f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f4cbe06f0df4304848b8eda1ff37205",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c4f925714374888ac146f16bfc288f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4-k32YuwqEU",
        "outputId": "6a7a6d65-9dac-4e81-9bef-434f1f2d6e1c"
      },
      "source": [
        "for elem in dataset[0]:\n",
        "  print(elem)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title\n",
            "context\n",
            "question\n",
            "id\n",
            "answer_text\n",
            "answer_start\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEV5JJH3wx0C"
      },
      "source": [
        "def format_time(elapsed):\n",
        "\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8SMM-p-w4TG",
        "outputId": "b288e4fd-9d02-4727-9294-dc2b63cb592d"
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "all_input_ids = []\n",
        "attention_masks = []\n",
        "segment_ids = [] \n",
        "start_positions = []\n",
        "end_positions = []\n",
        "\n",
        "num_dropped = 0\n",
        "\n",
        "update_interval = 10000\n",
        "\n",
        "print('Tokenizing {:,} examples...'.format(len(dataset)))\n",
        "\n",
        "for (ex_num, ex) in enumerate(dataset):\n",
        "\n",
        "    if (ex_num % update_interval) == 0 and not (ex_num == 0):\n",
        "        \n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        ex_per_sec = (time.time() - t0) / ex_num\n",
        "        remaining_sec = ex_per_sec * (len(dataset) - ex_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "\n",
        "        print('  Example {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(ex_num, len(dataset), elapsed, remaining))\n",
        "\n",
        "\n",
        "    answer_tokens = tokenizer.tokenize(ex['answer_text'])\n",
        "\n",
        "    sentinel_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "\n",
        "    start_char_i = ex['answer_start']\n",
        "    end_char_i = start_char_i + len(ex['answer_text'])\n",
        "    context_w_sentinel = ex['context'][:start_char_i] + \\\n",
        "                         sentinel_str + \\\n",
        "                         ex['context'][end_char_i:]\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        ex['question'], \n",
        "        context_w_sentinel,\n",
        "        add_special_tokens = True,\n",
        "        max_length = 384,\n",
        "        pad_to_max_length = True,\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt', \n",
        "    )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids']\n",
        "\n",
        "    is_mask_token = (input_ids[0] == tokenizer.mask_token_id)\n",
        "\n",
        "    mask_token_indeces = is_mask_token.nonzero(as_tuple=False)[:, 0]\n",
        "\n",
        "    if not len(mask_token_indeces) == len(answer_tokens):\n",
        "        \n",
        "        num_dropped += 1\n",
        "\n",
        "        continue\n",
        "\n",
        "\n",
        "    start_index = mask_token_indeces[0]\n",
        "    end_index = mask_token_indeces[-1]\n",
        "\n",
        "    answer_token_ids = tokenizer.encode(answer_tokens, \n",
        "                                        add_special_tokens=False, \n",
        "                                        return_tensors='pt')\n",
        "\n",
        "    input_ids[0, start_index : end_index + 1] = answer_token_ids\n",
        "   \n",
        "    all_input_ids.append(input_ids)\n",
        "\n",
        "    attention_masks.append(encoded_dict['attention_mask'])    \n",
        "\n",
        "    segment_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "    start_positions.append(start_index)\n",
        "    end_positions.append(end_index)\n",
        "\n",
        "all_input_ids = torch.cat(all_input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "segment_ids = torch.cat(segment_ids, dim=0)\n",
        "\n",
        "start_positions = torch.tensor(start_positions)\n",
        "end_positions = torch.tensor(end_positions)\n",
        "\n",
        "print('DONE.  Tokenization took {:}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing 87,599 examples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Example  10,000  of   87,599.    Elapsed: 0:00:27. Remaining: 0:03:27\n",
            "  Example  20,000  of   87,599.    Elapsed: 0:00:49. Remaining: 0:02:45\n",
            "  Example  30,000  of   87,599.    Elapsed: 0:01:14. Remaining: 0:02:23\n",
            "  Example  40,000  of   87,599.    Elapsed: 0:01:44. Remaining: 0:02:04\n",
            "  Example  50,000  of   87,599.    Elapsed: 0:02:12. Remaining: 0:01:39\n",
            "  Example  60,000  of   87,599.    Elapsed: 0:02:41. Remaining: 0:01:14\n",
            "  Example  70,000  of   87,599.    Elapsed: 0:03:09. Remaining: 0:00:48\n",
            "  Example  80,000  of   87,599.    Elapsed: 0:03:38. Remaining: 0:00:21\n",
            "DONE.  Tokenization took 0:04:01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4naz2xOTxQlR",
        "outputId": "3d3302d4-b1ad-4bb4-93a4-aa420d21d600"
      },
      "source": [
        "print('Tokenized {:,} examples.'.format(len(all_input_ids)))\n",
        "\n",
        "print('\\nDropped {:,} examples.'.format(num_dropped))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized 87,502 examples.\n",
            "\n",
            "Dropped 97 examples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJlk7EQnxTHx",
        "outputId": "3dc6c44b-5adc-4814-ef36-c459b6ca2ac3"
      },
      "source": [
        "dataset = TensorDataset(all_input_ids, \n",
        "                        attention_masks, \n",
        "                        segment_ids, \n",
        "                        start_positions, \n",
        "                        end_positions)\n",
        "\n",
        "print('Dataset size: {:} samples'.format(len(dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size: 87502 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa_RoTuyxVfx",
        "outputId": "69778b7c-6390-49db-9bf7-5b087f35aba7"
      },
      "source": [
        "train_size = int(0.98 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85,751 training samples\n",
            "1,751 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV_CfdUAxYpm",
        "outputId": "904d928c-30e5-471b-957b-635a24317a0a"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler, SequentialSampler\n",
        "\n",
        "import numpy.random\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset, \n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "print('{:,} training batches & {:,} validation batches'.format(len(train_dataloader), len(validation_dataloader)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5,360 training batches & 110 validation batches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "d3f8597df35a43ce98a28d56e25c8f97",
            "2e09624e5f5c4387a79dc788f510683a",
            "0f8fbf01350b49188e0bc9b8d84c6b4b",
            "cd5a9d471431401eb6611dc5ce58d92e",
            "47f8a164741143ed9179c6e6a242d7be",
            "e672ea092795409c844592ff41cfd383",
            "0bc96583e2db4657b01532fc078056e9",
            "9732a8f2d6484056884157b0c63d42eb",
            "fb57798fce5d4774903822352d7c6a84",
            "ddf9bb9eb66444e7bcf6c9fb13badc92",
            "14b21152050d469bb2c5da1ccd149929",
            "3453d35e94d7441d9a2a4f06b3a6d61f",
            "321c334df06749a5bb020606ecac2551",
            "69cb3415614c4ae1b850c400c87cafae",
            "acee8d5223eb4bf587d124a50b4b2d9d",
            "c1d79a6612574773a9dde1ae1714ff22"
          ]
        },
        "id": "kUkhJ3dVxbi5",
        "outputId": "43f4c487-cc86-45a5-a109-6e3369fadf61"
      },
      "source": [
        "model = BertForQuestionAnswering.from_pretrained(\n",
        "    \"bert-base-cased\", \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False\n",
        ")\n",
        "\n",
        "desc = model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3f8597df35a43ce98a28d56e25c8f97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb57798fce5d4774903822352d7c6a84",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omv4AeuxxeRx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neS2lXLuxilK",
        "outputId": "321aa83a-4b39-4d2c-cc4b-31f0c6742d9e"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    \n",
        "    print('Training {:,} batches...'.format(len(train_dataloader)))\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    update_interval = 100\n",
        "\n",
        "\n",
        "    num_batches = len(train_dataloader)\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % update_interval == 0 and not step == 0:\n",
        "            \n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            step_per_sec = (time.time() - t0) / step\n",
        "            remaining_sec = step_per_sec * (num_batches - step)\n",
        "            remaining = format_time(remaining_sec)\n",
        "\n",
        "            print('  Batch {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(step, num_batches, elapsed, remaining))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_seg_ids = batch[2].to(device)\n",
        "        b_start_pos = batch[3].to(device)\n",
        "        b_end_pos = batch[4].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        token_type_ids = b_seg_ids,\n",
        "                        start_positions=b_start_pos,\n",
        "                        end_positions=b_end_pos)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        start_logits = outputs[1]\n",
        "        end_logits = outputs[2]\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "       \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    t0_val = time.time()\n",
        "\n",
        "    pred_start, pred_end, true_start, true_end = [], [], [], []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_seg_ids = batch[2].to(device)\n",
        "        b_start_pos = batch[3].to(device)\n",
        "        b_end_pos = batch[4].to(device)\n",
        "       \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=b_seg_ids, \n",
        "                            attention_mask=b_input_mask,\n",
        "                            start_positions=b_start_pos,\n",
        "                            end_positions=b_end_pos)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        start_logits = outputs[1]\n",
        "        end_logits = outputs[2]\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        start_logits = start_logits.detach().cpu().numpy()\n",
        "        end_logits = end_logits.detach().cpu().numpy()\n",
        "        \n",
        "        b_start_pos = b_start_pos.to('cpu').numpy()\n",
        "        b_end_pos = b_end_pos.to('cpu').numpy()\n",
        "\n",
        "        answer_start = np.argmax(start_logits, axis=1)\n",
        "        answer_end = np.argmax(end_logits, axis=1)\n",
        "\n",
        "        pred_start.append(answer_start)\n",
        "        pred_end.append(answer_end)\n",
        "        true_start.append(b_start_pos)\n",
        "        true_end.append(b_end_pos)\n",
        "\n",
        "    pred_start = np.concatenate(pred_start, axis=0)\n",
        "    pred_end = np.concatenate(pred_end, axis=0)\n",
        "    true_start = np.concatenate(true_start, axis=0)\n",
        "    true_end = np.concatenate(true_end, axis=0)\n",
        "        \n",
        "    num_start_correct = np.sum(pred_start == true_start)\n",
        "    num_end_correct = np.sum(pred_end == true_end)\n",
        "\n",
        "    total_correct = num_start_correct + num_end_correct\n",
        "    total_indeces = len(true_start) + len(true_end)\n",
        "\n",
        "    avg_val_accuracy = float(total_correct) / float(total_indeces)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0_val)\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training 5,360 batches...\n",
            "  Batch     100  of    5,360.    Elapsed: 0:02:04. Remaining: 1:48:53\n",
            "  Batch     200  of    5,360.    Elapsed: 0:04:21. Remaining: 1:52:03\n",
            "  Batch     300  of    5,360.    Elapsed: 0:06:37. Remaining: 1:51:35\n",
            "  Batch     400  of    5,360.    Elapsed: 0:08:53. Remaining: 1:50:13\n",
            "  Batch     500  of    5,360.    Elapsed: 0:11:09. Remaining: 1:48:27\n",
            "  Batch     600  of    5,360.    Elapsed: 0:13:26. Remaining: 1:46:34\n",
            "  Batch     700  of    5,360.    Elapsed: 0:15:42. Remaining: 1:44:30\n",
            "  Batch     800  of    5,360.    Elapsed: 0:17:58. Remaining: 1:42:27\n",
            "  Batch     900  of    5,360.    Elapsed: 0:20:15. Remaining: 1:40:20\n",
            "  Batch   1,000  of    5,360.    Elapsed: 0:22:32. Remaining: 1:38:13\n",
            "  Batch   1,100  of    5,360.    Elapsed: 0:24:48. Remaining: 1:36:02\n",
            "  Batch   1,200  of    5,360.    Elapsed: 0:27:04. Remaining: 1:33:51\n",
            "  Batch   1,300  of    5,360.    Elapsed: 0:29:20. Remaining: 1:31:37\n",
            "  Batch   1,400  of    5,360.    Elapsed: 0:31:36. Remaining: 1:29:24\n",
            "  Batch   1,500  of    5,360.    Elapsed: 0:33:52. Remaining: 1:27:10\n",
            "  Batch   1,600  of    5,360.    Elapsed: 0:36:09. Remaining: 1:24:56\n",
            "  Batch   1,700  of    5,360.    Elapsed: 0:38:25. Remaining: 1:22:42\n",
            "  Batch   1,800  of    5,360.    Elapsed: 0:40:41. Remaining: 1:20:28\n",
            "  Batch   1,900  of    5,360.    Elapsed: 0:42:57. Remaining: 1:18:13\n",
            "  Batch   2,000  of    5,360.    Elapsed: 0:45:13. Remaining: 1:15:58\n",
            "  Batch   2,100  of    5,360.    Elapsed: 0:47:29. Remaining: 1:13:43\n",
            "  Batch   2,200  of    5,360.    Elapsed: 0:49:45. Remaining: 1:11:28\n",
            "  Batch   2,300  of    5,360.    Elapsed: 0:52:01. Remaining: 1:09:12\n",
            "  Batch   2,400  of    5,360.    Elapsed: 0:54:17. Remaining: 1:06:57\n",
            "  Batch   2,500  of    5,360.    Elapsed: 0:56:33. Remaining: 1:04:42\n",
            "  Batch   2,600  of    5,360.    Elapsed: 0:58:50. Remaining: 1:02:27\n",
            "  Batch   2,700  of    5,360.    Elapsed: 1:01:06. Remaining: 1:00:11\n",
            "  Batch   2,800  of    5,360.    Elapsed: 1:03:21. Remaining: 0:57:55\n",
            "  Batch   2,900  of    5,360.    Elapsed: 1:05:37. Remaining: 0:55:40\n",
            "  Batch   3,000  of    5,360.    Elapsed: 1:07:53. Remaining: 0:53:24\n",
            "  Batch   3,100  of    5,360.    Elapsed: 1:10:09. Remaining: 0:51:09\n",
            "  Batch   3,200  of    5,360.    Elapsed: 1:12:26. Remaining: 0:48:54\n",
            "  Batch   3,300  of    5,360.    Elapsed: 1:14:42. Remaining: 0:46:38\n",
            "  Batch   3,400  of    5,360.    Elapsed: 1:16:58. Remaining: 0:44:22\n",
            "  Batch   3,500  of    5,360.    Elapsed: 1:19:14. Remaining: 0:42:07\n",
            "  Batch   3,600  of    5,360.    Elapsed: 1:21:30. Remaining: 0:39:51\n",
            "  Batch   3,700  of    5,360.    Elapsed: 1:23:46. Remaining: 0:37:35\n",
            "  Batch   3,800  of    5,360.    Elapsed: 1:26:02. Remaining: 0:35:19\n",
            "  Batch   3,900  of    5,360.    Elapsed: 1:28:18. Remaining: 0:33:03\n",
            "  Batch   4,000  of    5,360.    Elapsed: 1:30:34. Remaining: 0:30:48\n",
            "  Batch   4,100  of    5,360.    Elapsed: 1:32:51. Remaining: 0:28:32\n",
            "  Batch   4,200  of    5,360.    Elapsed: 1:35:07. Remaining: 0:26:16\n",
            "  Batch   4,300  of    5,360.    Elapsed: 1:37:23. Remaining: 0:24:00\n",
            "  Batch   4,400  of    5,360.    Elapsed: 1:39:39. Remaining: 0:21:44\n",
            "  Batch   4,500  of    5,360.    Elapsed: 1:41:55. Remaining: 0:19:29\n",
            "  Batch   4,600  of    5,360.    Elapsed: 1:44:11. Remaining: 0:17:13\n",
            "  Batch   4,700  of    5,360.    Elapsed: 1:46:28. Remaining: 0:14:57\n",
            "  Batch   4,800  of    5,360.    Elapsed: 1:48:44. Remaining: 0:12:41\n",
            "  Batch   4,900  of    5,360.    Elapsed: 1:51:01. Remaining: 0:10:25\n",
            "  Batch   5,000  of    5,360.    Elapsed: 1:53:17. Remaining: 0:08:09\n",
            "  Batch   5,100  of    5,360.    Elapsed: 1:55:33. Remaining: 0:05:53\n",
            "  Batch   5,200  of    5,360.    Elapsed: 1:57:49. Remaining: 0:03:37\n",
            "  Batch   5,300  of    5,360.    Elapsed: 2:00:05. Remaining: 0:01:22\n",
            "\n",
            "  Average training loss: 1.29\n",
            "  Training epcoh took: 2:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation Loss: 0.94\n",
            "  Validation took: 0:00:52\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training 5,360 batches...\n",
            "  Batch     100  of    5,360.    Elapsed: 0:02:16. Remaining: 1:59:38\n",
            "  Batch     200  of    5,360.    Elapsed: 0:04:33. Remaining: 1:57:23\n",
            "  Batch     300  of    5,360.    Elapsed: 0:06:49. Remaining: 1:54:58\n",
            "  Batch     400  of    5,360.    Elapsed: 0:09:05. Remaining: 1:52:41\n",
            "  Batch     500  of    5,360.    Elapsed: 0:11:22. Remaining: 1:50:25\n",
            "  Batch     600  of    5,360.    Elapsed: 0:13:37. Remaining: 1:48:04\n",
            "  Batch     700  of    5,360.    Elapsed: 0:15:53. Remaining: 1:45:46\n",
            "  Batch     800  of    5,360.    Elapsed: 0:18:09. Remaining: 1:43:30\n",
            "  Batch     900  of    5,360.    Elapsed: 0:20:25. Remaining: 1:41:13\n",
            "  Batch   1,000  of    5,360.    Elapsed: 0:22:42. Remaining: 1:38:57\n",
            "  Batch   1,100  of    5,360.    Elapsed: 0:24:58. Remaining: 1:36:42\n",
            "  Batch   1,200  of    5,360.    Elapsed: 0:27:14. Remaining: 1:34:25\n",
            "  Batch   1,300  of    5,360.    Elapsed: 0:29:30. Remaining: 1:32:07\n",
            "  Batch   1,400  of    5,360.    Elapsed: 0:31:47. Remaining: 1:29:53\n",
            "  Batch   1,500  of    5,360.    Elapsed: 0:34:03. Remaining: 1:27:38\n",
            "  Batch   1,600  of    5,360.    Elapsed: 0:36:20. Remaining: 1:25:23\n",
            "  Batch   1,700  of    5,360.    Elapsed: 0:38:37. Remaining: 1:23:08\n",
            "  Batch   1,800  of    5,360.    Elapsed: 0:40:53. Remaining: 1:20:51\n",
            "  Batch   1,900  of    5,360.    Elapsed: 0:43:08. Remaining: 1:18:33\n",
            "  Batch   2,000  of    5,360.    Elapsed: 0:45:25. Remaining: 1:16:18\n",
            "  Batch   2,100  of    5,360.    Elapsed: 0:47:42. Remaining: 1:14:03\n",
            "  Batch   2,200  of    5,360.    Elapsed: 0:49:58. Remaining: 1:11:47\n",
            "  Batch   2,300  of    5,360.    Elapsed: 0:52:15. Remaining: 1:09:31\n",
            "  Batch   2,400  of    5,360.    Elapsed: 0:54:32. Remaining: 1:07:15\n",
            "  Batch   2,500  of    5,360.    Elapsed: 0:56:48. Remaining: 1:04:59\n",
            "  Batch   2,600  of    5,360.    Elapsed: 0:59:05. Remaining: 1:02:43\n",
            "  Batch   2,700  of    5,360.    Elapsed: 1:01:22. Remaining: 1:00:27\n",
            "  Batch   2,800  of    5,360.    Elapsed: 1:03:39. Remaining: 0:58:12\n",
            "  Batch   2,900  of    5,360.    Elapsed: 1:05:55. Remaining: 0:55:55\n",
            "  Batch   3,000  of    5,360.    Elapsed: 1:08:12. Remaining: 0:53:39\n",
            "  Batch   3,100  of    5,360.    Elapsed: 1:10:29. Remaining: 0:51:23\n",
            "  Batch   3,200  of    5,360.    Elapsed: 1:12:46. Remaining: 0:49:07\n",
            "  Batch   3,300  of    5,360.    Elapsed: 1:15:02. Remaining: 0:46:50\n",
            "  Batch   3,400  of    5,360.    Elapsed: 1:17:18. Remaining: 0:44:34\n",
            "  Batch   3,500  of    5,360.    Elapsed: 1:19:34. Remaining: 0:42:17\n",
            "  Batch   3,600  of    5,360.    Elapsed: 1:21:51. Remaining: 0:40:01\n",
            "  Batch   3,700  of    5,360.    Elapsed: 1:24:07. Remaining: 0:37:44\n",
            "  Batch   3,800  of    5,360.    Elapsed: 1:26:23. Remaining: 0:35:28\n",
            "  Batch   3,900  of    5,360.    Elapsed: 1:28:39. Remaining: 0:33:11\n",
            "  Batch   4,000  of    5,360.    Elapsed: 1:30:56. Remaining: 0:30:55\n",
            "  Batch   4,100  of    5,360.    Elapsed: 1:33:12. Remaining: 0:28:38\n",
            "  Batch   4,200  of    5,360.    Elapsed: 1:35:28. Remaining: 0:26:22\n",
            "  Batch   4,300  of    5,360.    Elapsed: 1:37:44. Remaining: 0:24:06\n",
            "  Batch   4,400  of    5,360.    Elapsed: 1:40:00. Remaining: 0:21:49\n",
            "  Batch   4,500  of    5,360.    Elapsed: 1:42:17. Remaining: 0:19:33\n",
            "  Batch   4,600  of    5,360.    Elapsed: 1:44:33. Remaining: 0:17:16\n",
            "  Batch   4,700  of    5,360.    Elapsed: 1:46:50. Remaining: 0:15:00\n",
            "  Batch   4,800  of    5,360.    Elapsed: 1:49:07. Remaining: 0:12:44\n",
            "  Batch   4,900  of    5,360.    Elapsed: 1:51:23. Remaining: 0:10:27\n",
            "  Batch   5,000  of    5,360.    Elapsed: 1:53:39. Remaining: 0:08:11\n",
            "  Batch   5,100  of    5,360.    Elapsed: 1:55:55. Remaining: 0:05:55\n",
            "  Batch   5,200  of    5,360.    Elapsed: 1:58:11. Remaining: 0:03:38\n",
            "  Batch   5,300  of    5,360.    Elapsed: 2:00:27. Remaining: 0:01:22\n",
            "\n",
            "  Average training loss: 0.78\n",
            "  Training epcoh took: 2:01:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 0.93\n",
            "  Validation took: 0:00:53\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training 5,360 batches...\n",
            "  Batch     100  of    5,360.    Elapsed: 0:02:16. Remaining: 1:59:26\n",
            "  Batch     200  of    5,360.    Elapsed: 0:04:33. Remaining: 1:57:24\n",
            "  Batch     300  of    5,360.    Elapsed: 0:06:50. Remaining: 1:55:09\n",
            "  Batch     400  of    5,360.    Elapsed: 0:09:06. Remaining: 1:52:53\n",
            "  Batch     500  of    5,360.    Elapsed: 0:11:22. Remaining: 1:50:31\n",
            "  Batch     600  of    5,360.    Elapsed: 0:13:38. Remaining: 1:48:12\n",
            "  Batch     700  of    5,360.    Elapsed: 0:15:55. Remaining: 1:45:58\n",
            "  Batch     800  of    5,360.    Elapsed: 0:18:12. Remaining: 1:43:43\n",
            "  Batch     900  of    5,360.    Elapsed: 0:20:28. Remaining: 1:41:26\n",
            "  Batch   1,000  of    5,360.    Elapsed: 0:22:44. Remaining: 1:39:08\n",
            "  Batch   1,100  of    5,360.    Elapsed: 0:25:00. Remaining: 1:36:50\n",
            "  Batch   1,200  of    5,360.    Elapsed: 0:27:16. Remaining: 1:34:32\n",
            "  Batch   1,300  of    5,360.    Elapsed: 0:29:33. Remaining: 1:32:17\n",
            "  Batch   1,400  of    5,360.    Elapsed: 0:31:49. Remaining: 1:30:00\n",
            "  Batch   1,500  of    5,360.    Elapsed: 0:34:06. Remaining: 1:27:45\n",
            "  Batch   1,600  of    5,360.    Elapsed: 0:36:23. Remaining: 1:25:30\n",
            "  Batch   1,700  of    5,360.    Elapsed: 0:38:40. Remaining: 1:23:15\n",
            "  Batch   1,800  of    5,360.    Elapsed: 0:40:58. Remaining: 1:21:00\n",
            "  Batch   1,900  of    5,360.    Elapsed: 0:43:14. Remaining: 1:18:43\n",
            "  Batch   2,000  of    5,360.    Elapsed: 0:45:29. Remaining: 1:16:26\n",
            "  Batch   2,100  of    5,360.    Elapsed: 0:47:46. Remaining: 1:14:09\n",
            "  Batch   2,200  of    5,360.    Elapsed: 0:50:02. Remaining: 1:11:52\n",
            "  Batch   2,300  of    5,360.    Elapsed: 0:52:18. Remaining: 1:09:35\n",
            "  Batch   2,400  of    5,360.    Elapsed: 0:54:34. Remaining: 1:07:18\n",
            "  Batch   2,500  of    5,360.    Elapsed: 0:56:50. Remaining: 1:05:01\n",
            "  Batch   2,600  of    5,360.    Elapsed: 0:59:07. Remaining: 1:02:45\n",
            "  Batch   2,700  of    5,360.    Elapsed: 1:01:23. Remaining: 1:00:29\n",
            "  Batch   2,800  of    5,360.    Elapsed: 1:03:40. Remaining: 0:58:12\n",
            "  Batch   2,900  of    5,360.    Elapsed: 1:05:56. Remaining: 0:55:56\n",
            "  Batch   3,000  of    5,360.    Elapsed: 1:08:13. Remaining: 0:53:40\n",
            "  Batch   3,100  of    5,360.    Elapsed: 1:10:30. Remaining: 0:51:23\n",
            "  Batch   3,200  of    5,360.    Elapsed: 1:12:46. Remaining: 0:49:07\n",
            "  Batch   3,300  of    5,360.    Elapsed: 1:15:03. Remaining: 0:46:51\n",
            "  Batch   3,400  of    5,360.    Elapsed: 1:17:19. Remaining: 0:44:34\n",
            "  Batch   3,500  of    5,360.    Elapsed: 1:19:36. Remaining: 0:42:18\n",
            "  Batch   3,600  of    5,360.    Elapsed: 1:21:52. Remaining: 0:40:02\n",
            "  Batch   3,700  of    5,360.    Elapsed: 1:24:08. Remaining: 0:37:45\n",
            "  Batch   3,800  of    5,360.    Elapsed: 1:26:25. Remaining: 0:35:29\n",
            "  Batch   3,900  of    5,360.    Elapsed: 1:28:42. Remaining: 0:33:12\n",
            "  Batch   4,000  of    5,360.    Elapsed: 1:30:57. Remaining: 0:30:55\n",
            "  Batch   4,100  of    5,360.    Elapsed: 1:33:14. Remaining: 0:28:39\n",
            "  Batch   4,200  of    5,360.    Elapsed: 1:35:30. Remaining: 0:26:23\n",
            "  Batch   4,300  of    5,360.    Elapsed: 1:37:47. Remaining: 0:24:06\n",
            "  Batch   4,400  of    5,360.    Elapsed: 1:40:04. Remaining: 0:21:50\n",
            "  Batch   4,500  of    5,360.    Elapsed: 1:42:20. Remaining: 0:19:33\n",
            "  Batch   4,600  of    5,360.    Elapsed: 1:44:35. Remaining: 0:17:17\n",
            "  Batch   4,700  of    5,360.    Elapsed: 1:46:52. Remaining: 0:15:00\n",
            "  Batch   4,800  of    5,360.    Elapsed: 1:49:09. Remaining: 0:12:44\n",
            "  Batch   4,900  of    5,360.    Elapsed: 1:51:25. Remaining: 0:10:28\n",
            "  Batch   5,000  of    5,360.    Elapsed: 1:53:40. Remaining: 0:08:11\n",
            "  Batch   5,100  of    5,360.    Elapsed: 1:55:56. Remaining: 0:05:55\n",
            "  Batch   5,200  of    5,360.    Elapsed: 1:58:12. Remaining: 0:03:38\n",
            "  Batch   5,300  of    5,360.    Elapsed: 2:00:28. Remaining: 0:01:22\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 2:01:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation Loss: 1.00\n",
            "  Validation took: 0:00:53\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO-JWpFo1JpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c143dd06-0783-453a-929b-60ccc75b96f4"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(os.path.join('/content/drive/MyDrive/dev-v1.1.json'), \"r\", encoding=\"utf-8\") as reader:\n",
        "    input_data = json.load(reader)[\"data\"]\n",
        "\n",
        "\n",
        "print_count = 0\n",
        "\n",
        "print('Unpacking SQuAD Examples...')\n",
        "\n",
        "print('Articles:')\n",
        "\n",
        "examples = []\n",
        "\n",
        "for entry in input_data:\n",
        "\n",
        "    title = entry[\"title\"]\n",
        "    print('  ', title)\n",
        "\n",
        "    for paragraph in entry[\"paragraphs\"]:\n",
        "        \n",
        "        context_text = GoogleTranslator(source='en', target='fa').translate(paragraph[\"context\"])\n",
        "        \n",
        "        for qa in paragraph[\"qas\"]:\n",
        "            \n",
        "            ex = {}\n",
        "\n",
        "            ex['qas_id'] = qa[\"id\"]\n",
        "\n",
        "            ex['question_text'] = GoogleTranslator(source='en', target='fa').translate(qa[\"question\"])\n",
        "\n",
        "            ex['answers'] = GoogleTranslator(source='en', target='fa').translate(qa[\"answers\"])\n",
        "\n",
        "            ex['title'] = title\n",
        "            ex['context_text'] = GoogleTranslator(source='en', target='fa').translate(context_text)\n",
        "\n",
        "            examples.append(ex)\n",
        "\n",
        "print('DONE!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpacking SQuAD Examples...\n",
            "Articles:\n",
            "   Super_Bowl_50\n",
            "   Warsaw\n",
            "   Normans\n",
            "   Nikola_Tesla\n",
            "   Computational_complexity_theory\n",
            "   Teacher\n",
            "   Martin_Luther\n",
            "   Southern_California\n",
            "   Sky_(United_Kingdom)\n",
            "   Victoria_(Australia)\n",
            "   Huguenot\n",
            "   Steam_engine\n",
            "   Oxygen\n",
            "   1973_oil_crisis\n",
            "   Apollo_program\n",
            "   European_Union_law\n",
            "   Amazon_rainforest\n",
            "   Ctenophora\n",
            "   Fresno,_California\n",
            "   Packet_switching\n",
            "   Black_Death\n",
            "   Geology\n",
            "   Newcastle_upon_Tyne\n",
            "   Victoria_and_Albert_Museum\n",
            "   American_Broadcasting_Company\n",
            "   Genghis_Khan\n",
            "   Pharmacy\n",
            "   Immune_system\n",
            "   Civil_disobedience\n",
            "   Construction\n",
            "   Private_school\n",
            "   Harvard_University\n",
            "   Jacksonville,_Florida\n",
            "   Economic_inequality\n",
            "   Doctor_Who\n",
            "   University_of_Chicago\n",
            "   Yuan_dynasty\n",
            "   Kenya\n",
            "   Intergovernmental_Panel_on_Climate_Change\n",
            "   Chloroplast\n",
            "   Prime_number\n",
            "   Rhine\n",
            "   Scottish_Parliament\n",
            "   Islamism\n",
            "   Imperialism\n",
            "   United_Methodist_Church\n",
            "   French_and_Indian_War\n",
            "   Force\n",
            "DONE!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2CJ2DCb1Tv-"
      },
      "source": [
        "def good_update_interval(total_iters, num_desired_updates):\n",
        "\n",
        "    exact_interval = total_iters / num_desired_updates\n",
        "\n",
        "    order_of_mag = len(str(total_iters)) - 1\n",
        "\n",
        "    round_mag = order_of_mag - 1\n",
        "\n",
        "    update_interval = int(round(exact_interval, -round_mag))\n",
        "\n",
        "    if update_interval == 0:\n",
        "        update_interval = 1\n",
        "\n",
        "    return update_interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usEFUwhG1cF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d754bd-2e71-4f0e-9f36-41ef6eb1e43e"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "start_positions = []\n",
        "end_positions = []\n",
        "\n",
        "num_clipped_answers = 0\n",
        "num_impossible = 0\n",
        "\n",
        "update_interval = good_update_interval(\n",
        "            total_iters = len(examples), \n",
        "            num_desired_updates = 15\n",
        "        )\n",
        "\n",
        "print('Processing {:,} examples...'.format(len(examples)))\n",
        "\n",
        "for (ex_num, ex) in enumerate(examples):\n",
        "\n",
        "    if (ex_num % update_interval) == 0 and not (ex_num == 0):\n",
        "\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        ex_per_sec = (time.time() - t0) / ex_num\n",
        "        remaining_sec = ex_per_sec * (len(examples) - ex_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "\n",
        "        print('  Example {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(ex_num, len(examples), elapsed, remaining))\n",
        "\n",
        "    start_options = []\n",
        "    end_options = []\n",
        "\n",
        "    encoded_stored = False\n",
        "\n",
        "    for answer in ex['answers']:\n",
        "\n",
        "        answer_tokens = tokenizer.tokenize(answer['text'])\n",
        "\n",
        "        sentinel_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "\n",
        "        start_char_i = answer['answer_start']\n",
        "        end_char_i = start_char_i + len(answer['text'])\n",
        "\n",
        "        context_w_sentinel = ex['context_text'][:start_char_i] + \\\n",
        "                            sentinel_str + \\\n",
        "                            ex['context_text'][end_char_i:]\n",
        "\n",
        "        input_ids = tokenizer.encode(\n",
        "            ex['question_text'], \n",
        "            context_w_sentinel,\n",
        "            add_special_tokens = True, \n",
        "            pad_to_max_length = False,\n",
        "            truncation = False,\n",
        "        )\n",
        "\n",
        "        mask_token_indeces = np.where(np.array(input_ids) == tokenizer.mask_token_id)[0]\n",
        "\n",
        "        assert(len(mask_token_indeces) == len(answer_tokens))           \n",
        "\n",
        "        start_index = mask_token_indeces[0]\n",
        "        end_index = mask_token_indeces[-1]\n",
        "\n",
        "        start_options.append(start_index)\n",
        "        end_options.append(end_index)\n",
        "    \n",
        "    start_positions.append(start_options)\n",
        "    end_positions.append(end_options)\n",
        "\n",
        "print('DONE.  Tokenization took {:}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 10,570 examples...\n",
            "  Example   1,000  of   10,570.    Elapsed: 0:00:07. Remaining: 0:01:04\n",
            "  Example   2,000  of   10,570.    Elapsed: 0:00:13. Remaining: 0:00:55\n",
            "  Example   3,000  of   10,570.    Elapsed: 0:00:19. Remaining: 0:00:49\n",
            "  Example   4,000  of   10,570.    Elapsed: 0:00:29. Remaining: 0:00:47\n",
            "  Example   5,000  of   10,570.    Elapsed: 0:00:39. Remaining: 0:00:44\n",
            "  Example   6,000  of   10,570.    Elapsed: 0:00:48. Remaining: 0:00:36\n",
            "  Example   7,000  of   10,570.    Elapsed: 0:00:57. Remaining: 0:00:29\n",
            "  Example   8,000  of   10,570.    Elapsed: 0:01:05. Remaining: 0:00:21\n",
            "  Example   9,000  of   10,570.    Elapsed: 0:01:12. Remaining: 0:00:13\n",
            "  Example  10,000  of   10,570.    Elapsed: 0:01:21. Remaining: 0:00:05\n",
            "DONE.  Tokenization took 0:01:27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqK7dGbW1fTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3bb60f-270c-4d8b-a4ed-3b859ee6dce4"
      },
      "source": [
        "num_impossible = 0\n",
        "num_clipped = 0\n",
        "\n",
        "for (start_options, end_options) in zip(start_positions, end_positions):\n",
        "\n",
        "    is_possible = False\n",
        "\n",
        "    for i in range(0, len(start_options)):\n",
        "        \n",
        "        if (start_options[i] < 384) and (end_options[i] < 384):\n",
        "            is_possible = True\n",
        "        \n",
        "        if (start_options[i] > 384) or (end_options[i] > 384):\n",
        "            num_clipped += 1\n",
        "\n",
        "    if not is_possible:\n",
        "        num_impossible += 1\n",
        "\n",
        "print('')\n",
        "\n",
        "print('Samples w/ all answers clipped: {:,} of {:,} ({:.2%})'.format(num_impossible, len(examples), float(num_impossible) / float(len(examples))))\n",
        "\n",
        "addtl_clipped = num_clipped - (num_impossible * 3)\n",
        "total_answers = len(examples) * 3\n",
        "print('\\n    Additional clipped answers: {:,} of {:,}'.format(addtl_clipped, total_answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples w/ all answers clipped: 47 of 10,570 (0.44%)\n",
            "\n",
            "    Additional clipped answers: 33 of 31,710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCncrS2M1klF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d5c645-cbb2-47ee-99e2-2aec575e752e"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "all_input_ids = []\n",
        "attention_masks = []\n",
        "segment_ids = [] \n",
        "\n",
        "update_interval = good_update_interval(\n",
        "            total_iters = len(examples), \n",
        "            num_desired_updates = 15\n",
        "        )\n",
        "\n",
        "print('Tokenizing {:,} examples...'.format(len(examples)))\n",
        "\n",
        "for (ex_num, ex) in enumerate(examples):\n",
        "\n",
        "    if (ex_num % update_interval) == 0 and not (ex_num == 0):\n",
        "\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        ex_per_sec = (time.time() - t0) / ex_num\n",
        "        remaining_sec = ex_per_sec * (len(examples) - ex_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "\n",
        "        print('  Example {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(ex_num, len(examples), elapsed, remaining))\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        ex['question_text'], \n",
        "        ex['context_text'],\n",
        "        add_special_tokens = True,\n",
        "        max_length = 384, \n",
        "        pad_to_max_length = True,\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = 'pt',\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids']\n",
        "  \n",
        "    all_input_ids.append(input_ids)\n",
        "\n",
        "    attention_masks.append(encoded_dict['attention_mask'])    \n",
        "\n",
        "    segment_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "all_input_ids = torch.cat(all_input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "segment_ids = torch.cat(segment_ids, dim=0)\n",
        "\n",
        "print('DONE.  Tokenization took {:}'.format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing 10,570 examples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Example   1,000  of   10,570.    Elapsed: 0:00:02. Remaining: 0:00:22\n",
            "  Example   2,000  of   10,570.    Elapsed: 0:00:04. Remaining: 0:00:19\n",
            "  Example   3,000  of   10,570.    Elapsed: 0:00:07. Remaining: 0:00:17\n",
            "  Example   4,000  of   10,570.    Elapsed: 0:00:09. Remaining: 0:00:15\n",
            "  Example   5,000  of   10,570.    Elapsed: 0:00:12. Remaining: 0:00:14\n",
            "  Example   6,000  of   10,570.    Elapsed: 0:00:15. Remaining: 0:00:12\n",
            "  Example   7,000  of   10,570.    Elapsed: 0:00:18. Remaining: 0:00:09\n",
            "  Example   8,000  of   10,570.    Elapsed: 0:00:21. Remaining: 0:00:07\n",
            "  Example   9,000  of   10,570.    Elapsed: 0:00:23. Remaining: 0:00:04\n",
            "  Example  10,000  of   10,570.    Elapsed: 0:00:26. Remaining: 0:00:01\n",
            "DONE.  Tokenization took 0:00:27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YPf8_jf1p6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169f0cc6-6d8e-4395-9f53-9ac1a953460d"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "pred_start = []\n",
        "pred_end = []\n",
        "\n",
        "num_test_samples = all_input_ids.shape[0]\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "num_batches = int(np.ceil(num_test_samples / batch_size))\n",
        "\n",
        "print('Evaluating on {:,} test batches...'.format(num_batches))\n",
        "\n",
        "batch_num = 0\n",
        "\n",
        "for start_i in range(0, num_test_samples, batch_size):\n",
        "    \n",
        "    if ((batch_num % 50) == 0) and not (batch_num == 0):\n",
        "\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        \n",
        "        batches_per_sec = (time.time() - t0) / batch_num\n",
        "        remaining_sec = batches_per_sec * (num_batches - batch_num)\n",
        "        remaining = format_time(remaining_sec)\n",
        "\n",
        "        print('  Batch {:>7,}  of  {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(batch_num, num_batches, elapsed, remaining))\n",
        "\n",
        "    end_i = min(start_i + batch_size, num_test_samples)\n",
        "\n",
        "    b_input_ids = all_input_ids[start_i:end_i, :]\n",
        "    b_attn_masks = attention_masks[start_i:end_i, :]\n",
        "    b_seg_ids = segment_ids[start_i:end_i, :]   \n",
        "\n",
        "    b_input_ids = b_input_ids.to(device)\n",
        "    b_attn_masks = b_attn_masks.to(device)\n",
        "    b_seg_ids = b_seg_ids.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_attn_masks,\n",
        "                        token_type_ids=b_seg_ids)\n",
        "                        \n",
        "    start_logits = outputs[0]\n",
        "    end_logits = outputs[1]\n",
        "    start_logits = start_logits.detach().cpu().numpy()\n",
        "    end_logits = end_logits.detach().cpu().numpy()\n",
        "    \n",
        "    answer_start = np.argmax(start_logits, axis=1)\n",
        "    answer_end = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    pred_start.append(answer_start)\n",
        "    pred_end.append(answer_end)\n",
        "\n",
        "    batch_num += 1\n",
        "\n",
        "pred_start = np.concatenate(pred_start, axis=0)\n",
        "pred_end = np.concatenate(pred_end, axis=0)\n",
        "\n",
        "print('    DONE.')\n",
        "\n",
        "print('\\nEvaluation took {:.0f} seconds.'.format(time.time() - t0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating on 661 test batches...\n",
            "  Batch      50  of      661.    Elapsed: 0:00:20. Remaining: 0:04:09\n",
            "  Batch     100  of      661.    Elapsed: 0:00:41. Remaining: 0:03:51\n",
            "  Batch     150  of      661.    Elapsed: 0:01:03. Remaining: 0:03:33\n",
            "  Batch     200  of      661.    Elapsed: 0:01:25. Remaining: 0:03:15\n",
            "  Batch     250  of      661.    Elapsed: 0:01:47. Remaining: 0:02:56\n",
            "  Batch     300  of      661.    Elapsed: 0:02:10. Remaining: 0:02:36\n",
            "  Batch     350  of      661.    Elapsed: 0:02:32. Remaining: 0:02:15\n",
            "  Batch     400  of      661.    Elapsed: 0:02:55. Remaining: 0:01:54\n",
            "  Batch     450  of      661.    Elapsed: 0:03:19. Remaining: 0:01:33\n",
            "  Batch     500  of      661.    Elapsed: 0:03:42. Remaining: 0:01:11\n",
            "  Batch     550  of      661.    Elapsed: 0:04:05. Remaining: 0:00:50\n",
            "  Batch     600  of      661.    Elapsed: 0:04:29. Remaining: 0:00:27\n",
            "  Batch     650  of      661.    Elapsed: 0:04:53. Remaining: 0:00:05\n",
            "    DONE.\n",
            "\n",
            "Evaluation took 298 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PiGzCnK1ssk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2ce54f-c20c-4782-916f-8e7c627b38f0"
      },
      "source": [
        "total_correct = 0\n",
        "\n",
        "for i in range(0, len(pred_start)):\n",
        "\n",
        "    match_options = []\n",
        "\n",
        "    for j in range (0, len(start_positions[i])):\n",
        "    \n",
        "        matches = 0\n",
        "\n",
        "        if pred_start[i] == start_positions[i][j]:\n",
        "            matches += 1\n",
        "\n",
        "        if pred_end[i] == end_positions[i][j]:\n",
        "            matches += 1\n",
        "\n",
        "        match_options.append(matches)\n",
        "\n",
        "    total_correct += (max(match_options))\n",
        "\n",
        "\n",
        "total_indeces = len(pred_start) + len(pred_end)\n",
        "\n",
        "print('Correctly predicted indeces: {:,} of {:,} ({:.2%})'.format(\n",
        "    total_correct,\n",
        "    total_indeces,\n",
        "    float(total_correct) / float(total_indeces)\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correctly predicted indeces: 16,378 of 21,140 (77.47%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd9KEFa81yhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f23dd01-f79b-43aa-aad9-f4c03813243e"
      },
      "source": [
        "f1s = []\n",
        "\n",
        "for i in range(0, len(pred_start)):\n",
        "\n",
        "    pred_span = set(range(pred_start[i], pred_end[i] + 1))\n",
        "\n",
        "\n",
        "    f1_options = []\n",
        "\n",
        "    for j in range (0, len(start_positions[i])):\n",
        "    \n",
        "        true_span = set(range(start_positions[i][j], end_positions[i][j] + 1))    \n",
        "\n",
        "        num_same = len(pred_span.intersection(true_span))    \n",
        "\n",
        "        if num_same == 0:\n",
        "            f1_options.append(0)\n",
        "            continue\n",
        "    \n",
        "        precision = float(num_same) / float(len(pred_span))\n",
        "     \n",
        "        recall = float(num_same) / float(len(true_span))\n",
        "\n",
        "        f1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "        f1_options.append(f1)\n",
        "\n",
        "    f1s.append(max(f1_options))\n",
        "\n",
        "\n",
        "\n",
        "print('Average F1 Score: {:.3f}'.format(np.mean(f1s)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average F1 Score: 0.791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jalD_hy11ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393f524a-132f-4814-809a-e3b83fdea51f"
      },
      "source": [
        "output_dir = './pretrained_model/'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  \n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./pretrained_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./pretrained_model/tokenizer_config.json',\n",
              " './pretrained_model/special_tokens_map.json',\n",
              " './pretrained_model/vocab.txt',\n",
              " './pretrained_model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}